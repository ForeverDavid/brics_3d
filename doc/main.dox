/** 
 * @mainpage BRICS_3D Documentation pages 
 *  
 * @section intro Introduction 
 * 
 * BRICS_3D is the BRICS library for 3D perception and modeling. It implements the processing stages to create a 3D model (e.g. triangle representation) out of data from laser range finders, ToF cameras or depth images from stereo cameras. 
 * This library is biased towards 3D perception and modeling for mobile manipulation applications.
 * 
 * The 3D perception and modeling domain can be classified into several subareas: <i>depth
 * perception, filtering, registration, segmentation, mesh generation and visualization.</i>
 *
 * @subsection depth_perception Depth perception
 * For depth perception various kinds of sensors exist. Laser scanners emit laser beams that
 * are reflected when the beams hit the surface. The traveling time of the light is used to deduce the
 * distance. Time-of-Flight cameras follow the same principle, but some devices measure the phase
 * shift of a modulated frequency rather than the traveled time. Stereo camera systems consists of                                                                                             
 * two cameras that are mounted on a fixed baseline. As the baseline is known, distances to corresponding 
 * points can be calculated via triangulation. Sensor data is often encoded into depth or
 * range images. Although the depth perception is a crucial step for 3D perception, it is assumed in
 * this work that depth images are already given. Algorithms in this domain are typically hardware
 * dependent. This library will provide functionality to turn a depth image into a point cloud representation.
 * 
 * @subsection filtering Filtering
 * A filter is an algorithm that is able to process a data stream, in this case point cloud data.
 * Three major filtering techniques are often applied to point clouds: noise reduction, size reduction
 * and normal estimation.
 *
 * Noise reduction filters try to remedy shortcomings of the sensors measurements. Size reduction
 * filters sub-sample the input data to get an approximated but smaller amount of data. The less
 * input data an algorithms has, the faster the processing is. Normal estimation filters are needed to
 * compute a normal vector for each point in a point cloud. The normal represents the plane normal
 * vector of an underlying patch of the surface. Many algorithms requires point clouds with normals
 * to further process the data. The filtering stage can be regarded as optional, but it is a valuable
 * contribution to create more robust or faster results.
 * 
 * @subsection registration Registration
 * Registration, also sometimes referred as <i>matching</i>, is the process of merging captures from
 * different viewpoints into one global, consistent coordinate frame. This is a robotic problem, because
 * mobile robots move in their environment and thus are able to perceive the environment from
 * different perspectives. Some tasks require to integrate all perceived scene captures into one consistent 
 * model to reason about it (for example to plan a path). The most prominent algorithm to
 * solve the registration problem for point clouds is the Iterative Closest Point (ICP) method.
 * 
 * @subsection segmentation Segmentation
 * Segmentation means a spatial partition of point clouds into subsets that belong to different
 * objects. 3D models of special shapes, like boxes, cylinders or balls are often fitted into these
 * regions to model the perceived objects. <br>
 * With respect to a mobile manipulation application that needs a triangle set representation of an 
 * environment this stage can be regarded as optional. However, the segmentation of data might
 * be helpful to recognize objects that can be grasped, for example.
 *  
 * @subsection mesh_generation Mesh generation
 * The goal of the mesh generation step is to transform a 3D point cloud into a triangle mesh.
 * Similar terms are <i>meshing, shape recovery, surface recovery, surface reconstruction, model retrieval,
 * inverse CAD or geometric modeling</i> (in computer vision). Most of these terms are used
 * in a broader context that already includes some filtering or registration steps. The notion mesh
 * generation is used here in a more limited way restricted to the part of model transformation from
 * point cloud to triangle mesh.
 * 
 * @subsection visualization Visualization 
 * Visualization, or rendering, is the process of displaying the 3D models. This involves a
 * transformation from the models into a 2D image, which can be displayed on a monitor. This
 * task is often performed by specialized hardware: graphic adapters. The graphic adapters offer a
 * software interface to render the models that consist of primitive elements like points, lines or polygons.
 * One standardized interface is OpenGL, which allows operating system independent access
 * the graphic adapters. <br>
 * Robotic applications do not necessarily need to visualize the generated models, but visualization 
 * can serve as a development or debug tool to visually inspect intermediate results or the
 * output of certain algorithms. 
 *
 *
 * @section installation Installation  
 * @subsection lin Linux
 * See here: https://trac.best-of-robotics.org/brics/wiki/BRICS_3D/Installation
 *
 * @subsection win Windows
 * See here: https://trac.best-of-robotics.org/brics/wiki/BRICS_3D/Installation 
 */
 
/**
 * @namespace BRICS_3D 
 * @brief The BRICS 3D perception and modeling library.
 */
  
/**
 * @defgroup registration Registration
 * @brief This module contains algorithms for registration of point clouds.
 *
 * The module comprises in particular the Iterative Closest Point algorithm (ICP) and atomic sub components.
 *
 */
  
 /**
 * @defgroup nearestNeighbor NearestNeighbor
 * @brief This module contains algorithms for nearest neighbor search
 *
 */
  